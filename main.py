import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
# import xgboost as xgb
from catboost import CatBoostRegressor
from langchain_experimental.agents import create_pandas_dataframe_agent
from langchain_community.utilities import DuckDuckGoSearchAPIWrapper
from langchain.memory import ConversationBufferMemory
from langchain.chat_models import ChatOllama
from langchain_community.callbacks import StreamlitCallbackHandler
from langchain_core.runnables import RunnableConfig
from langchain.agents.agent_types import AgentType
from langchain.agents import AgentExecutor, Tool, create_react_agent
from sklearn.ensemble import RandomForestRegressor
from langchain.chains import LLMMathChain
from langchain.agents import AgentExecutor
from langchain.agents.mrkl.base import ZeroShotAgent
from langchain.chains.llm import LLMChain
from plasTeX import TeXDocument
from sklearn.preprocessing import LabelEncoder
from IPython.display import Math
from langchain_core.prompts import PromptTemplate
from langchain import hub


st.set_page_config(
    page_title="Rossmann LLM Agent", page_icon="ğŸ¦œğŸ”—ğŸ§ ", layout="wide", initial_sidebar_state="collapsed"
)
st.title("ğŸ§  Rossmann åº—é“ºè¥ä¸šé¢åˆ†æ")

# # Sidebar API Key
# openai_api_key = st.sidebar.text_input("ğŸ”‘ è¾“å…¥ä½ çš„ OpenAI API Key", type="password")
# os.environ["OPENAI_API_KEY"] = openai_api_key

# ä¸Šä¼ æ–‡ä»¶
# trainFile = st.file_uploader("è¯·ä¸Šä¼ è®­ç»ƒæ•°æ®æ–‡ä»¶", type="csv", accept_multiple_files=True)
# storeFile = st.file_uploader("è¯·ä¸Šä¼ é™„åŠ æ•°æ®æ–‡ä»¶", type="csv", accept_multiple_files=True)
# ä¸€æ¬¡ä¸Šä¼ å¤šä¸ªæ–‡ä»¶
uploaded_files = st.file_uploader("è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶", type=["csv", "txt"], accept_multiple_files=True)

monthDict = {
    "ä¸€æœˆä»½": 1,
    "äºŒæœˆä»½": 2,
    "ä¸‰æœˆä»½": 3,
    "å››æœˆä»½": 4,
    "äº”æœˆä»½": 5,
    "å…­æœˆä»½": 6,
    "ä¸ƒæœˆä»½": 7,
    "å…«æœˆä»½": 8,
    "ä¹æœˆä»½": 9,
    "åæœˆä»½": 10,
    "åä¸€æœˆä»½": 11,
    "åäºŒæœˆä»½": 12
}

selected = st.selectbox("è¯·é€‰æ‹©æœˆä»½:", list(monthDict.keys()))
month = monthDict[selected]

with st.form(key="form"):
    submit_clicked = st.form_submit_button("ç¡®è®¤æäº¤")

if submit_clicked:
    trainFlag, storeFlag, fieldFlag = False, False, False
    for uploaded_file in uploaded_files:
        if "train" in uploaded_file.name:
            trainFlag = True
        if "store" in uploaded_file.name:
            storeFlag = True
        if "field" in uploaded_file.name:
            fieldFlag = True
    if not trainFlag:
        st.error("âŒ ç¼ºå°‘åŒ…å«è®­ç»ƒæ•°æ®çš„æ–‡ä»¶ï¼Œè¯·ä¸Šä¼ è®­ç»ƒæ•°æ®æ–‡ä»¶")
    elif not storeFlag:
        st.error("âŒ ç¼ºå°‘åŒ…å«é™„åŠ æ•°æ®çš„æ–‡ä»¶ï¼Œè¯·ä¸Šä¼ é™„åŠ æ•°æ®æ–‡ä»¶")
    elif not fieldFlag:
        st.error("âŒ ç¼ºå°‘åŒ…å«å­—æ®µè§£é‡Šçš„æ–‡ä»¶ï¼Œè¯·ä¸Šä¼ ç›¸å…³æ•°æ®æ–‡ä»¶")
    else:
        st.success(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼å°†åˆ†æ{selected}çš„è¥ä¸šé¢æ•°æ®")
        with st.spinner("è¯»å–ä¸å¤„ç†æ•°æ®ä¸­..."):
            for uploaded_file in uploaded_files:
                if "train" in uploaded_file.name:
                    train = pd.read_csv(uploaded_file, parse_dates=['Date'])
                elif "store" in uploaded_file.name:
                    store = pd.read_csv(uploaded_file)
                else:
                    fieldContent = uploaded_file.read().decode("utf-8")  # è§£ç ä¸ºæ–‡æœ¬
                    # with open(uploaded_file, 'r', encoding='utf-8') as file:
                    #     fieldContent = file.read()
                
            # print(train.columns)
            
            # æœæŸ¥è¿‘3ä¸ªæœˆçš„æ•°æ®
            # train = train[(train['Date'] >= '2015-04-01') & (train['Date'] <= '2015-07-31')]
            train['Month'] = train['Date'].dt.to_period('M')
            uniqueMonths = train['Month'].sort_values(ascending=False).unique()
            # top4 = uniqueMonths[:4]
            # march = str(train['Date'].dt.year.max())+"-"+"03"
            # train = train[train['Month']==march]
            
            marchPeriods = uniqueMonths[uniqueMonths.month == month]
            periodMarch = marchPeriods[0]
            period_array = pd.arrays.PeriodArray([periodMarch.ordinal, (periodMarch-1).ordinal], freq='M')
            train = train[train['Month'].isin(period_array)]
            train = train[train['Open'] == 1]  # ä¿ç•™å½“å¤©æœ‰è¥ä¸šçš„æ•°æ®
            
            monthSales = train.groupby(['Store', 'Month'])['Sales'].sum().unstack() # è®¡ç®—æ¯å®¶å•†åº—æ¯ä¸ªæœˆçš„æ€»è¥ä¸šé¢
            # print(monthSales.head())
            monthSales.columns = monthSales.columns.astype(str)
            marFeb = period_array.strftime('%Y-%m').tolist()
            
            # è®¡ç®—ç¯æ¯”ç‡
            for i in range(len(marFeb)-1):
                monthSales[marFeb[i]] = (monthSales[marFeb[i]] - monthSales[marFeb[i+1]]) / monthSales[marFeb[i+1]]
            # print(monthSales.head())
            months = monthSales[marFeb[:1]].reset_index()
            months.columns = ['Store'] + marFeb[:1]
            # print(months.head())
            
            features = train.groupby(['Store', 'Month']).agg({
                'Promo': 'mean',
                'Customers': 'mean',
                'SchoolHoliday': 'mean',
                'StateHoliday': lambda x: (x != '0').mean()
            }).reset_index()
            # åªä¿ç•™3æœˆä»½æ•°æ®
            features = features[features['Month']==periodMarch]
            features = features.merge(store, on='Store', how='left')

            # print(features.head())
            merged = months.merge(features, on='Store', how='left')

            # for col in ['StoreType', 'Assortment']:
            #     merged[col] = LabelEncoder().fit_transform(merged[col].astype(str))
            
            # # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
            # if 'ml' not in st.session_state:
            #     st.session_state.ml = False
            # if 'agent' not in st.session_state:
            #     st.session_state.agent = False
    
        st.subheader("ğŸ“ˆ ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆMLï¼‰")
        # if st.button("å¼€å§‹MLåˆ†æ"):
        st.session_state.ml = True
        for col in ['StoreType', 'Assortment']:
            merged[col] = LabelEncoder().fit_transform(merged[col].astype(str))
        Xlist = ['Promo', 'Customers', 'SchoolHoliday', 'StateHoliday', 'StoreType', 'Assortment', 'Promo2', 'CompetitionDistance']
        y = merged[marFeb[0]]
        
        modelCB = CatBoostRegressor(iterations=100, learning_rate=0.1, depth=4, verbose=0, loss_function='RMSE', od_type='Iter', eval_metric='RMSE', od_wait=50)
        modelRF = RandomForestRegressor()
        modelList = [modelCB, modelRF]
        colors = ["Blues_d", "Reds_d"]
        fig, axes = plt.subplots(1, len(modelList), figsize=(9*len(modelList), 6))
        for i in range(len(modelList)):
            if modelList[i].__class__.__name__ == 'CatBoostRegressor':
                modelList[i].fit(merged[Xlist], y)
            else:
                merged = merged.fillna(0)
                modelList[i].fit(merged[Xlist], y)
            importance = pd.Series(modelList[i].feature_importances_, index=Xlist)
            importance = importance.sort_values(ascending=False)
            
            sns.barplot(
                x=importance.values,
                y=importance.index,
                palette=colors[i],
                ax=axes[i]
            )
            axes[i].set_title(f'{modelList[i].__class__.__name__} Feature Importance', fontsize=12)
            axes[i].tick_params(axis='both', labelsize=8)
            axes[i].set_xlabel('Importance Score', fontsize=9)
            axes[i].set_ylabel('Features', fontsize=9)
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for j, v in enumerate(importance):
                axes[i].text(v, j, f'{v:.3f}', va='center', fontsize=6)
        
        plt.tight_layout()
        st.pyplot(plt.gcf())

        
        st.subheader("ğŸ§  å› ç´ è§£é‡Šåˆ†æ")
        llm = ChatOllama(model="deepseek-r1:14b")
        search = DuckDuckGoSearchAPIWrapper()
        # memory = ConversationBufferMemory(memory_key="chat_history")
        llm_math_chain = LLMMathChain.from_llm(llm)
        tools = [
            Tool(
                name="Search",
                func=search.run,
                description="useful for when you need to answer questions about current events. You should ask targeted questions",
            ),
            Tool(
                name="Calculator",
                func=llm_math_chain.run,
                description="useful for when you need to answer questions about math",
            )
        ]

        # template = """Answer the following questions as best you can. You have access to the following tools:

        #     {tools}

        #     è¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼:

        #     é—®é¢˜ï¼šä½ å¿…é¡»å›ç­”çš„è¾“å…¥é—®é¢˜
        #     æ€è€ƒï¼šä½ åº”è¯¥å§‹ç»ˆæ€è€ƒè¯¥åšä»€ä¹ˆ
        #     è¡Œä¸ºï¼šè¦é‡‡å–çš„è¡Œä¸ºï¼Œåº”è¯¥æ˜¯ [{tool_names}] ä¹‹ä¸€æˆ–æ— éœ€ä½¿ç”¨tool
        #     è¡Œä¸ºè¾“å…¥ï¼šè¡Œä¸ºçš„è¾“å…¥
        #     è§‚å¯Ÿï¼šè¡Œä¸ºçš„ç»“æœâ€¦â€¦
        #     æ€è€ƒï¼šæˆ‘ç°åœ¨çŸ¥é“æœ€ç»ˆç­”æ¡ˆäº†
        #     æœ€ç»ˆç­”æ¡ˆï¼šåŸå§‹è¾“å…¥é—®é¢˜çš„æœ€ç»ˆç­”æ¡ˆ

        #     å¼€å§‹!

        #     é—®é¢˜: {input}
        #     æ€è€ƒ:{agent_scratchpad}
        # """
        
        agent = create_pandas_dataframe_agent(
            llm,
            merged,
            verbose=True,
            agent_type=AgentType.OPENAI_FUNCTIONS,
            handle_parsing_errors=True
        )
        
        # agentExecutor = AgentExecutor(agent=agent, tools=tools, handle_parsing_errors=True)
        
        # react_agent = create_react_agent(llm, agent.tools, template)
        # agentExecutor = AgentExecutor(agent=react_agent, tools=tools, handle_parsing_errors=True)
        
        
        userInput = """
            ä½ æ˜¯ä¸€ä½ç²¾é€šæ•°æ®åˆ†æçš„æ•°æ®ç§‘å­¦å®¶ï¼Œä¸‹é¢æœ‰ä¸€ä¸ªæ ¼å¼ä¸ºDataFrameçš„æ•°æ®é›†åˆï¼ŒåŒ…å«è¶…è¿‡1000å®¶å•†åº—çš„è¥ä¸šé¢ç¯æ¯”ç‡åŠå…¶ä»–å› ç´ å­—æ®µã€‚
            æ•°æ®é›†ä¸­åˆ—åä¸ºY-Mæ ¼å¼çš„åˆ—æ•°æ®åˆ™æ˜¯æ¯å®¶å•†åº—æœ€è¿‘çš„{month}æœˆä»½çš„è¥ä¸šé¢ç¯æ¯”ï¼ˆè¯¥æ•°æ®è‹¥æ˜¯æ­£æ•°ä¸ºå¢é•¿ï¼Œè´Ÿæ•°ä¸ºä¸‹é™ï¼‰ï¼Œè¯·æ ¹æ®è¯¥åˆ—æ•°æ®çš„æ•°å€¼ï¼ˆè¿™ä¸‰åˆ—æ•°å€¼æ˜¯è¥ä¸šé¢çš„ç¯æ¯”å¢é•¿/ä¸‹é™ç‡ï¼‰ï¼Œç»“åˆå…¶å®ƒå› ç´ å­—æ®µå¦‚Promoã€Customersã€StoreTypeã€CompetitionDistanceç­‰ï¼Œ
            åˆ†ææ‰€æœ‰å•†åº—æœ€è¿‘{month}æœˆä»½è¥ä¸šé¢å¢é•¿æˆ–ä¸‹é™çš„åŸå› ï¼Œå¹¶æ‰¾å‡ºä¸è¥ä¸šé¢ç¯æ¯”ç‡æœ€ç›¸å…³çš„å› ç´ å­—æ®µï¼ŒæŒ‰è´¡çŒ®åº¦æ’åºå¹¶è¾“å‡ºè¯¦ç»†è§£é‡Šã€‚
            
            æ³¨æ„ï¼šDataFrameçš„æ•°æ®å·²ç»è¿‡é¢„å¤„ç†
            
            å…¶ä¸­ï¼Œæ•°æ®çš„å­—æ®µè§£é‡Šå¦‚ä¸‹ï¼š
            {fieldContent}
        """
        prompt = PromptTemplate.from_template(userInput)
        userInput = prompt.format(month=month, fieldContent=fieldContent)
        
        st.session_state.agent = True
        # # assistantå“åº”å®¹å™¨
        # answer_container = st.chat_message("assistant", avatar="ğŸ¦œ")
        # st_callback = StreamlitCallbackHandler(answer_container)
        # cfg = RunnableConfig()
        # cfg["callbacks"] = [st_callback]
        with st.spinner("Agentåˆ†æä¸­..."):
            response = agent.run(userInput)
            # response = agentExecutor.invoke({"input":user_input}, cfg)
            
            # å°†åˆ†æç»“æœå†™å…¥markdownæ–‡ä»¶
            with open("/home/cpss/satoshiyuen/rossmann/analysis_result.md", "w", encoding="utf-8") as f:
                f.write(response)
            st.markdown("### ğŸ¤– åˆ†æç»“æœ")
            st.write(response)

else:
    st.info("è¯·ä¸Šä¼ å®Œæ•´æ•°æ®æ–‡ä»¶ï¼")